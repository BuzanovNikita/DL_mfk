{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgzQ5bscUnsm"
   },
   "source": [
    "# Домашнее задание №4\n",
    "\n",
    "##### Автор: [Татьяна Гайнцева](https://www.linkedin.com/in/tgaintseva/), @atmyre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dlo1UHiNUnsp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/velikiyburyat/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/velikiyburyat/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdRDK1t0Wgxy"
   },
   "source": [
    "Это домашнее задание состоит из двух частей. В первой части вам нужно реализовать правильную архитектуру сверточной нейросети. Во второй части — подобрать хорошую архитектуру и обучить ее на датасете CIFAR так, чтобы результаты метрики accuracy на тестовой части CIFAR были больше 60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmVeuJosbxFD"
   },
   "source": [
    "## Задача №1:\n",
    "В этом задании вам нужно заполнить пропуски в ячейке ниже, чтобы получилась сверточная нейросеть с заданными параметрами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwGlvTT-b5tW"
   },
   "source": [
    "Архитектура сети:\n",
    "**conv1 -> maxpool1 -> conv2 -> maxpool2 -> flatten -> fc1 -> fc2**\n",
    "\n",
    "- conv1: 3 фильтра размера (5, 5);\n",
    "- maxpool1: ядро размера 2;\n",
    "- conv2: 5 фильтров размера (3, 3);\n",
    "- maxpool2: ядро размера 2;\n",
    "- fc1: 100 нейронов на выходе;\n",
    "- fc2: 10 нейронов на выходе.\n",
    "\n",
    "После сверточных слоев и первого полносвязного слоя нужно применить функцию активации ReLU. **Важно:** для успешной сдачи задания функция активации должна быть применена с помощью F.ReLU (не с помощью nn.ReLU).\n",
    "\n",
    "**Нейросеть должна работать с изображениями размера 32х32. Никакие дополнительные параметры слоев, кроме указанных выше, задавать не нужно**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zEQy7-AEb9--"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # размер исходной картинки 32х32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(5,5)) #28x28\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2)) #14x14\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=(3,3)) #12x12\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2)) #6x6\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(6 * 6 * 5, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # размерность х ~ [64, 3, 32, 32]\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nouGfm_gDFD"
   },
   "source": [
    "### Проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMWATEWKgFgp"
   },
   "source": [
    "Ячейки ниже помогут проверить, что модель написана и работает правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xVbCt6AffvNp"
   },
   "outputs": [],
   "source": [
    "# Эта ячейка не должна выдавать ошибку.\n",
    "# Если при исполнении ячейки возникает ошибка, то в вашей реализации нейросети есть баги.\n",
    "img = torch.Tensor(np.random.random((32, 3, 32, 32)))\n",
    "model = ConvNet()\n",
    "out = model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmVRmDEfgdoH"
   },
   "source": [
    "Ячейка ниже проверяет, что устройство сети верное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iZ_t7mCDesVU"
   },
   "outputs": [],
   "source": [
    "# conv1\n",
    "assert model.conv1.kernel_size == (5, 5), \"неверный размер ядра у conv1\"\n",
    "assert model.conv1.in_channels == 3, \"неверный размер in_channels у conv1\"\n",
    "assert model.conv1.out_channels == 3, \"неверный размер out_channels у conv1\"\n",
    "\n",
    "# pool1\n",
    "assert model.pool1.kernel_size == (2, 2), \"неверный размер ядра у pool1\"\n",
    "\n",
    "# conv2\n",
    "assert model.conv2.kernel_size == (3, 3), \"неверный размер ядра у conv2\"\n",
    "assert model.conv2.in_channels == 3, \"неверный размер in_channels у conv2\"\n",
    "assert model.conv2.out_channels == 5, \"неверный размер out_channels у conv2\"\n",
    "\n",
    "# pool2\n",
    "assert model.pool1.kernel_size == (2, 2), \"неверный размер ядра у pool2\"\n",
    "\n",
    "# fc1\n",
    "assert model.fc1.out_features == 100, \"неверный размер out_features у fc1\"\n",
    "# fc2\n",
    "assert model.fc2.out_features == 10, \"неверный размер out_features у fc2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtKvuJRHqM_d"
   },
   "source": [
    "### Сдача задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QybQ4rtQgppH"
   },
   "source": [
    "Если обе ячейки отработали без ошибок, можно сдавать задание в первую задачу на Я.Контесте.\n",
    "Для этого нужно скопировать класс ConvNet в нужное место в `submission_template04.py` и отправить `submission_template04.py` в Я.Контест."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obC9bnWsUnsr"
   },
   "source": [
    "## Задача №2:\n",
    "Вернемся к задаче классификации картинок [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "__Ваша основная задача: реализовать весь пайплан обучения модели и добиться хорошего значения метрики accuracy на тестовой выборке.__\n",
    "Баллы за задание:\n",
    "- **0**, если accuracy на тестовой выборке <0.5;\n",
    "- **0.5**, если accuracy на тестовой выборке >0.5 и <0.6;\n",
    "- **1**, если accuracy на тестовой выборке >0.6;\n",
    "\n",
    "Код для обучения модели в данном задании полностью реализован. Вам нужно лишь написать код класса нейросети и поэкспериментировать с параметрами так, чтобы получить хорошее качество. В качестве основы архитектуры сети можно взять сеть из задачи №1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izGM3kjrhbCk"
   },
   "source": [
    "**! Перед выполнением этого задания рекомендуем включить GPU в настройках колаба.** Это поможет обучать нейросеть быстрее.\n",
    "\n",
    "Чтобы включить GPU, перейдите Edit->Notebook settings и выберите Hardware accelerator=GPU. Нажмите save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZUgd4OiDh4EP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5VkRn8eYCL3"
   },
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5-HED1XYV96"
   },
   "source": [
    "Код загрузки данных тот же, что был на занятии. Менять ничего не нужно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-31e0aCCUnss",
    "outputId": "5241934a-5da7-4422-bd1f-8d9400e9474c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10_data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██▍                      | 16285696/170498071 [00:15<02:22, 1082485.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# загружаем датасет из torchvision\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./cifar10_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test_data \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./cifar10_data\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor())\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# делим тренировочную часть на train и val\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# в тренировочную выборку отнесем 80% всех картинок\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchvision/datasets/cifar.py:65\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchvision/datasets/cifar.py:139\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles already downloaded and verified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgz_md5\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchvision/datasets/utils.py:434\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[1;32m    432\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[0;32m--> 434\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchvision/datasets/utils.py:144\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fpath)\n\u001b[0;32m--> 144\u001b[0m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchvision/datasets/utils.py:48\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_urlretrieve\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m, filename: \u001b[38;5;28mstr\u001b[39m, chunk_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m---> 48\u001b[0m         \u001b[43m_save_response_content\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchvision/datasets/utils.py:37\u001b[0m, in \u001b[0;36m_save_response_content\u001b[0;34m(content, destination, length)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_response_content\u001b[39m(\n\u001b[1;32m     32\u001b[0m     content: Iterator[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[1;32m     33\u001b[0m     destination: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     34\u001b[0m     length: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(destination, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total\u001b[38;5;241m=\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 37\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m content:\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[1;32m     40\u001b[0m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchvision/datasets/utils.py:48\u001b[0m, in \u001b[0;36m_urlretrieve.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_urlretrieve\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m, filename: \u001b[38;5;28mstr\u001b[39m, chunk_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m---> 48\u001b[0m         _save_response_content(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), filename, length\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 465\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# загружаем датасет из torchvision\n",
    "train_data = datasets.CIFAR10(root=\"./cifar10_data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.CIFAR10(root=\"./cifar10_data\", train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# делим тренировочную часть на train и val\n",
    "\n",
    "# в тренировочную выборку отнесем 80% всех картинок\n",
    "train_size = int(len(train_data) * 0.8)\n",
    "# в валидационную — остальные 20%\n",
    "val_size = len(train_data) - train_size\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
    "\n",
    "# заводим даталоадеры, которые будут генерировать батчи\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xJCM2lZYjtR"
   },
   "source": [
    "Посмотрим на несколько картинок из датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "R7ZBNxsLYvMP",
    "outputId": "4ba41b1a-8581-4b5d-bd98-01601c20ac60"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# получаем батч картинок\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_loader\u001b[49m:\n\u001b[1;32m     18\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# функция отрисовки картинок\n",
    "def show_images(images, labels):\n",
    "    f, axes= plt.subplots(1, 10, figsize=(30,5))\n",
    "\n",
    "    for i, axis in enumerate(axes):\n",
    "        # переводим картинку из тензора в numpy\n",
    "        img = images[i].numpy()\n",
    "        # переводим картинку в размерность (длина, ширина, цветовые каналы)\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(labels[i].numpy())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# получаем батч картинок\n",
    "for batch in train_loader:\n",
    "    images, labels = batch\n",
    "    break\n",
    "\n",
    "show_images(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAbF9VCHifUg"
   },
   "source": [
    "### Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN-AYLsyUnsu"
   },
   "source": [
    "Ниже — ячейка для построения модели. Не стоит сразу делать большую и сложную модель с большим количеством слоев: такая сеть будет обучаться очень долго и, скорее всего, переобучится.\n",
    "\n",
    "Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 60% accuracy.\n",
    "\n",
    "__Внимание: ваша модель должна быть представлена именно переменной `model`.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFaM1UeWaE4K"
   },
   "source": [
    "Идеи, что можно попробовать, чтобы улучшить результат сети:\n",
    "\n",
    "- попробовать разное количество сверточных и полносвязных слоев;\n",
    "- попробовать разное количество фильтров в сверточных слоях;\n",
    "- попробовать разное количество нейронов в скрытых полносвязных слоях;\n",
    "- попробовать добавить BatchNorm, как после полносвязных, так и после сверточных слоев. Обратите внимание, что для сверточных слоев используется [nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html). Аргумент num_features равен количеству фильтров (out_channels) сверточного слоя;\n",
    "- попробовать добавить/убрать max_pooling;\n",
    "- поменять learning_rate;\n",
    "- обучать сеть большее количество эпох.\n",
    "\n",
    "Если ваша модель переобучается (метрика на валидации нацинает становиться хуже), попробуйте уменьшить количество параметров модели. Если модель не переобучается, но показывает плохой результат, попробуйте увеличить количество параметров модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3UyozaPnUnsu"
   },
   "outputs": [],
   "source": [
    "# ВАШ КОД ЗДЕСЬ\n",
    "# объявите класс сверточной нейросети\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # размер исходной картинки 32х32\n",
    "\n",
    "        # conv 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(5,5)) #28x28\n",
    "        # pool 1\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2)) #14x14\n",
    "        # conv 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=9, kernel_size=(3,3)) #12x12\n",
    "        # pool 2\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2)) #6x6\n",
    "\n",
    "        # flatten\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # linear 1\n",
    "        self.fc1 = nn.Linear(6 * 6 * 9, 162)\n",
    "        # linear 2\n",
    "        self.fc2 = nn.Linear(162, 81)\n",
    "        # linear 3\n",
    "        self.fc3 = nn.Linear(81, 10)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # размерность х ~ [64, 3, 32, 32]\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "MFpILkiXhEz-"
   },
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1reimxeCh9BA"
   },
   "source": [
    "Ячейка ниже проверяет, доступен ли GPU и если да, то переносит нейросеть на GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "keaqEK3ug9rd"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKghv45uiEqo"
   },
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2onmgyzUntQ"
   },
   "source": [
    "Функция обучения сети (ее менять не нужно).\n",
    "\n",
    "Функция выводит текущие значения лосса и accuracy на train выборке каждые 50 итераций обучения. Также после каждой эпохи считается и выводится лосс и accuracy на val выборке. По этим значениям можно понимать, как хорошо обучается ваша модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jYsRSxVjUntR"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, loss_fn):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    num_correct = 0\n",
    "    num_elements = 0\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "\n",
    "        # так получаем текущий батч\n",
    "        X_batch, y_batch = batch\n",
    "        num_elements += len(y_batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(X_batch.to(device))\n",
    "\n",
    "            loss = loss_fn(logits, y_batch.to(device))\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            y_pred = torch.argmax(logits, dim=1)\n",
    "\n",
    "            num_correct += torch.sum(y_pred.cpu() == y_batch)\n",
    "\n",
    "    accuracy = num_correct / num_elements\n",
    "\n",
    "    return accuracy.numpy(), np.mean(losses)\n",
    "\n",
    "def train(model, loss_fn, optimizer, n_epoch=3):\n",
    "\n",
    "    # цикл обучения сети\n",
    "    for epoch in range(n_epoch):\n",
    "\n",
    "        print(\"Epoch:\", epoch+1)\n",
    "\n",
    "        model.train(True)\n",
    "\n",
    "        running_losses = []\n",
    "        running_accuracies = []\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            # так получаем текущий батч\n",
    "            X_batch, y_batch = batch\n",
    "\n",
    "            # forward pass (получение ответов на батч картинок)\n",
    "            logits = model(X_batch.to(device))\n",
    "\n",
    "            # вычисление лосса от выданных сетью ответов и правильных ответов на батч\n",
    "            loss = loss_fn(logits, y_batch.to(device))\n",
    "            running_losses.append(loss.item())\n",
    "\n",
    "            loss.backward() # backpropagation (вычисление градиентов)\n",
    "            optimizer.step() # обновление весов сети\n",
    "            optimizer.zero_grad() # обнуляем веса\n",
    "\n",
    "            # вычислим accuracy на текущем train батче\n",
    "            model_answers = torch.argmax(logits, dim=1)\n",
    "            train_accuracy = torch.sum(y_batch == model_answers.cpu()) / len(y_batch)\n",
    "            running_accuracies.append(train_accuracy)\n",
    "\n",
    "            # Логирование результатов\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(\"Средние train лосс и accuracy на последних 50 итерациях:\",\n",
    "                      np.mean(running_losses), np.mean(running_accuracies), end='\\n')\n",
    "\n",
    "        # после каждой эпохи получаем метрику качества на валидационной выборке\n",
    "        model.train(False)\n",
    "\n",
    "        val_accuracy, val_loss = evaluate(model, val_loader, loss_fn=loss_fn)\n",
    "        print(\"Эпоха {}/{}: val лосс и accuracy:\".format(epoch+1, n_epoch,),\n",
    "                      val_loss, val_accuracy, end='\\n')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEBr1qTOjfo3"
   },
   "source": [
    "Запускаем обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KYqzqj02jZly"
   },
   "outputs": [],
   "source": [
    "# снова объявим модель\n",
    "model = ConvNet()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# выбираем функцию потерь\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# выбираем алгоритм оптимизации и learning_rate.\n",
    "# вы можете экспериментировать с разными значениями learning_rate\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMgy5EGsnEZt",
    "outputId": "b3eee382-c5e9-4b64-dd8c-d1d0cb6688f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.0541331017017364 0.63\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.0440730732679366 0.62921876\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.0491788073380788 0.6276562\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.0475751753151417 0.62746096\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.045938447713852 0.62815624\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.0504580852389336 0.6265885\n",
      "Эпоха 1/20: val лосс и accuracy: 1.168608454761991 0.5885\n",
      "Epoch: 2\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.0115235376358032 0.63984376\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.0202603381872177 0.63851565\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.0178426249821981 0.63729167\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.0162667845189572 0.63785154\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.0203095608949662 0.63603127\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.0240853746732077 0.6353125\n",
      "Эпоха 2/20: val лосс и accuracy: 1.1482352982660768 0.6005\n",
      "Epoch: 3\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9860121774673462 0.64984375\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9894951364398002 0.6494531\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9981260524193446 0.6452604\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9973877112567425 0.64453125\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.0017533601522446 0.64303124\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 1.0064875255028407 0.64203125\n",
      "Эпоха 3/20: val лосс и accuracy: 1.1483513185173084 0.6014\n",
      "Epoch: 4\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9595566624403 0.65625\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9778391379117966 0.65046877\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9712935690085093 0.65416664\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.981358096152544 0.65058595\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9823129504919053 0.65\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9794293374816576 0.6513021\n",
      "Эпоха 4/20: val лосс и accuracy: 1.1458097050903708 0.6024\n",
      "Epoch: 5\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9329559183120728 0.67390627\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9355346828699111 0.6725781\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9388428739706676 0.66979164\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9434494809806346 0.66796875\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9538786853551865 0.6631563\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9597015093763669 0.6611198\n",
      "Эпоха 5/20: val лосс и accuracy: 1.1842558289029796 0.5905\n",
      "Epoch: 6\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9373792105913162 0.66125\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9346287786960602 0.6657031\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9359195780754089 0.666875\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9407195037603379 0.66453123\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.942122523188591 0.6639063\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9406997762123743 0.6654948\n",
      "Эпоха 6/20: val лосс и accuracy: 1.151155267171799 0.6018\n",
      "Epoch: 7\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9068776935338974 0.6767188\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.920314778983593 0.6725781\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9215843393405279 0.67265624\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9219283626973629 0.6713281\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9248147193193436 0.6705313\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.9227827597657839 0.67067707\n",
      "Эпоха 7/20: val лосс и accuracy: 1.1363202576424665 0.6092\n",
      "Epoch: 8\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8915967154502868 0.684375\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8916682615876198 0.6828125\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.89371577501297 0.68046874\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8912195225059986 0.68171877\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8983779119253159 0.68046874\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.899587487578392 0.6801042\n",
      "Эпоха 8/20: val лосс и accuracy: 1.1443187093279164 0.6065\n",
      "Epoch: 9\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8667872935533524 0.69140625\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8772259309887886 0.68789065\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8799838403860728 0.6871354\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.885019671022892 0.68472654\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.884033071398735 0.68496877\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8856957811117172 0.6851042\n",
      "Эпоха 9/20: val лосс и accuracy: 1.1467648216873219 0.6058\n",
      "Epoch: 10\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8424699544906616 0.70109373\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8488400042057037 0.69890624\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8556094626585643 0.6978125\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8596354258805513 0.69566405\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8654754368662834 0.69334376\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8648708090682824 0.6925521\n",
      "Эпоха 10/20: val лосс и accuracy: 1.1302633441177903 0.6178\n",
      "Epoch: 11\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8173187804222107 0.71015626\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8422020998597145 0.7025\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8473875121275584 0.7011458\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.855346387475729 0.69789064\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8532983689308167 0.696125\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8509821318586668 0.6968489\n",
      "Эпоха 11/20: val лосс и accuracy: 1.195800324534155 0.5973\n",
      "Epoch: 12\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8031468337774277 0.71453124\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8166842502355576 0.7097656\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8223640191555023 0.7060937\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8248745238780976 0.70632815\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8303124279975891 0.70303124\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8340030514200528 0.70252603\n",
      "Эпоха 12/20: val лосс и accuracy: 1.1575733271374065 0.6087\n",
      "Epoch: 13\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8073514646291733 0.70953125\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7990795466303825 0.715625\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7975334440668423 0.7175\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8024086090177298 0.71546876\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8048964189887047 0.7157813\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.813355894635121 0.7129167\n",
      "Эпоха 13/20: val лосс и accuracy: 1.1554045065952714 0.6081\n",
      "Epoch: 14\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7745474022626877 0.725625\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7828474998474121 0.72484374\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7865256617466608 0.72239584\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7938301885128021 0.71835935\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7976502771377564 0.7174063\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.8010375826557478 0.7157552\n",
      "Эпоха 14/20: val лосс и accuracy: 1.1512455408740196 0.6156\n",
      "Epoch: 15\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7684132948517799 0.7234375\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7723453395068646 0.72382814\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7722330109278361 0.725\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7811001378297806 0.72203124\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7826259322166443 0.72209376\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.78596614792943 0.7207292\n",
      "Эпоха 15/20: val лосс и accuracy: 1.183354040619674 0.6119\n",
      "Epoch: 16\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7459689211845398 0.73515624\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7493603377044201 0.7328125\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.755685441394647 0.7286979\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7629317820817232 0.72648436\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7668367360234261 0.72675\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7731929152707259 0.72489583\n",
      "Эпоха 16/20: val лосс и accuracy: 1.1921994944286953 0.607\n",
      "Epoch: 17\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7142444917559624 0.74546874\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7224594955146313 0.7402344\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7421096961696942 0.73333335\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7479627254605293 0.7329297\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7526110423207283 0.73315626\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7564538685977459 0.7309635\n",
      "Эпоха 17/20: val лосс и accuracy: 1.198596322612398 0.6088\n",
      "Epoch: 18\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.6986487478017807 0.75140625\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7208466032147407 0.74242187\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.72709424863259 0.74078125\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7364762387424707 0.73796874\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7392578994035721 0.73709375\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.740211755335331 0.73645836\n",
      "Эпоха 18/20: val лосс и accuracy: 1.1996550089234759 0.6086\n",
      "Epoch: 19\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.6870910626649857 0.759375\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7019190868735313 0.75\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7129470230142275 0.7434375\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7193390703201294 0.74347657\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.726348502755165 0.741125\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7327024681369464 0.7396875\n",
      "Эпоха 19/20: val лосс и accuracy: 1.198338375349713 0.6097\n",
      "Epoch: 20\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.6819486424326897 0.75375\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.6943013891577721 0.75078124\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7047291207313537 0.7475521\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.6987625729292631 0.75007814\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7122166654467583 0.745625\n",
      "Средние train лосс и accuracy на последних 50 итерациях: 0.7150208279987176 0.7445573\n",
      "Эпоха 20/20: val лосс и accuracy: 1.2275549617542583 0.6093\n"
     ]
    }
   ],
   "source": [
    "# запустим обучение модели\n",
    "# параметр n_epoch можно варьировать\n",
    "model = train(model, loss_fn, optimizer, n_epoch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-0bg_d9mQJc"
   },
   "source": [
    "### Получение метрики качества на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fdsfmmGUntS",
    "outputId": "6ad7d919-f3ab-4560-c0bb-ee9c6df294a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy на тесте 0.6126\n"
     ]
    }
   ],
   "source": [
    "test_accuracy, _ = evaluate(model, test_loader, loss_fn)\n",
    "print('Accuracy на тесте', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTWg3rx7oigY"
   },
   "source": [
    "Вы можете экспериментировать с разным устройством архитектуры нейросети и запускать ее обучение и проверять accuracy на тесте с помощью трех ячеек выше. Когда вы получили нужное значение accuracy на тесте, можете сдавать задание на Я.Контест."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1lUTTanUntT"
   },
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0D82xfkUntT",
    "outputId": "c451d871-101a-41bd-c32a-c145c71e919f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество на тесте выше 0.6, 1 балл\n"
     ]
    }
   ],
   "source": [
    "if test_accuracy <= 0.5:\n",
    "    print(\"Качество на тесте ниже 0.5, 0 баллов\")\n",
    "elif test_accuracy < 0.6:\n",
    "    print(\"Качество на тесте между 0.5 и 0.6, 0.5 баллов\")\n",
    "elif test_accuracy >= 0.6:\n",
    "    print(\"Качество на тесте выше 0.6, 1 балл\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaaib09bUntU"
   },
   "source": [
    "### Сдача задания\n",
    "В ячейке ниже реализован код для получения файла с обученной сетью. Запустите эти ячейки. Полученный файл model.pth отправьте в Я.Контест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "gnLPac1NUntV"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x = torch.randn((1, 3, 32, 32))\n",
    "torch.jit.save(torch.jit.trace(model.cpu(), (x)), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szdg0viDUntW"
   },
   "source": [
    "Теперь у вас во вкладке \"файлы\" лежит файл model.pth. Загрузите этот файл в Я.Контест. И на этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
